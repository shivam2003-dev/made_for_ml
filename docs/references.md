# References

## Primary Textbooks

### T1: Machine Learning by Tom M. Mitchell

**Mitchell, T. M.** (1997). *Machine Learning*. The McGraw-Hill Companies, Inc. Indian Edition.

- [Amazon](https://www.amazon.com/Machine-Learning-Tom-M-Mitchell/dp/0070428077)
- [McGraw-Hill](https://www.mheducation.com/highered/product/machine-learning-mitchell/M9780070428072.html)

This is the primary textbook for the course, covering fundamental concepts in machine learning including:
- Decision tree learning
- Neural networks
- Bayesian learning
- Instance-based learning
- Genetic algorithms

**Key Chapters**:
- Chapter 1: Introduction
- Chapter 3: Decision Tree Learning
- Chapter 4: Artificial Neural Networks
- Chapter 6: Bayesian Learning
- Chapter 8: Instance-Based Learning
- Chapter 9: Genetic Algorithms

### R1: Pattern Recognition & Machine Learning by Christopher M. Bishop

**Bishop, C. M.** (2006). *Pattern Recognition & Machine Learning*. Springer.

- [Springer](https://link.springer.com/book/10.1007/978-0-387-45528-0)
- [Amazon](https://www.amazon.com/Pattern-Recognition-Learning-Information-Statistics/dp/0387310738)
- [Free PDF (Author's Website)](https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf)

A comprehensive text with strong mathematical foundations, covering:
- Linear models for regression and classification
- Neural networks
- Kernel methods
- Bayesian approaches

**Key Chapters**:
- Chapter 1: Introduction
- Chapter 3: Linear Models for Regression
- Chapter 4: Linear Models for Classification
- Chapter 5: Neural Networks
- Chapter 7: Sparse Kernel Machines (SVMs)

### R2: Introduction to Data Mining by Tan, Steinbach, and Kumar

**Tan, P. N., Steinbach, M., & Kumar, V.** (2019). *Introduction To Data Mining* (2nd Edition). Pearson.

- [Pearson](https://www.pearson.com/en-us/subject-catalog/p/introduction-to-data-mining/P200000003431)
- [Amazon](https://www.amazon.com/Introduction-Data-Mining-Pang-Ning/dp/0133128903)
- [Author's Website](https://www-users.cse.umn.edu/~kumar001/dmbook/index.php)

Focuses on practical data mining techniques and algorithms:
- Classification
- Clustering
- Association analysis
- Anomaly detection

## Additional References

### Support Vector Machines

**Burges, C. J. C.** (1998). A Tutorial on Support Vector Machines for Pattern Recognition. *Data Mining and Knowledge Discovery*, 2(2), 121-167.

- [DOI: 10.1023/A:1009715923555](https://doi.org/10.1023/A:1009715923555)
- [PDF (ResearchGate)](https://www.researchgate.net/publication/220420529_A_Tutorial_on_Support_Vector_Machines_for_Pattern_Recognition)

Comprehensive tutorial covering:
- Mathematical foundations of SVMs
- Kernel methods
- Practical implementation considerations

### Research Papers

#### Bayesian Learning

1. **Domingos, P., & Pazzani, M.** (1997). On the optimality of the simple Bayesian classifier under zero-one loss. *Machine Learning*, 29(2-3), 103-130.

   - [DOI: 10.1023/A:1007413511361](https://doi.org/10.1023/A:1007413511361)
   - [PDF](https://link.springer.com/article/10.1023/A:1007413511361)

2. **Rissanen, J.** (1978). Modeling by shortest data description. *Automatica*, 14(5), 465-471. (MDL Principle)

   - [DOI: 10.1016/0005-1098(78)90005-5](https://doi.org/10.1016/0005-1098(78)90005-5)
   - [PDF](https://www.sciencedirect.com/science/article/abs/pii/0005109878900055)

#### Model Selection

3. **Geman, S., Bienenstock, E., & Doursat, R.** (1992). Neural networks and the bias/variance dilemma. *Neural Computation*, 4(1), 1-58.

   - [DOI: 10.1162/neco.1992.4.1.1](https://doi.org/10.1162/neco.1992.4.1.1)
   - [PDF](https://direct.mit.edu/neco/article-abstract/4/1/1/5515/Neural-Networks-and-the-Bias-Variance-Dilemma)

4. **Kohavi, R.** (1995). A study of cross-validation and bootstrap for accuracy estimation and model selection. *IJCAI*, 14(2), 1137-1145.

   - [PDF](https://www.ijcai.org/Proceedings/95-2/Papers/016.pdf)
   - [CiteSeerX](https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.48.529)

#### Linear Models

5. **Tibshirani, R.** (1996). Regression shrinkage and selection via the lasso. *Journal of the Royal Statistical Society*, 58(1), 267-288.

   - [DOI: 10.1111/j.2517-6161.1996.tb02080.x](https://doi.org/10.1111/j.2517-6161.1996.tb02080.x)
   - [PDF](https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.2517-6161.1996.tb02080.x)

6. **Hoerl, A. E., & Kennard, R. W.** (1970). Ridge regression: Biased estimation for nonorthogonal problems. *Technometrics*, 12(1), 55-67.

   - [DOI: 10.1080/00401706.1970.10488634](https://doi.org/10.1080/00401706.1970.10488634)
   - [PDF](https://www.tandfonline.com/doi/abs/10.1080/00401706.1970.10488634)

#### Decision Trees

7. **Quinlan, J. R.** (1986). Induction of decision trees. *Machine Learning*, 1(1), 81-106. (ID3 Algorithm)

   - [DOI: 10.1007/BF00116251](https://doi.org/10.1007/BF00116251)
   - [PDF](https://link.springer.com/article/10.1007/BF00116251)

8. **Quinlan, J. R.** (1993). *C4.5: Programs for Machine Learning*. Morgan Kaufmann.

   - [Amazon](https://www.amazon.com/C4-5-Programs-Machine-Learning/dp/1558602380)
   - [Morgan Kaufmann](https://www.elsevier.com/books/c45-programs-for-machine-learning/quinlan/978-1-55860-238-0)

9. **Breiman, L., Friedman, J., Stone, C. J., & Olshen, R. A.** (1984). *Classification and Regression Trees*. Wadsworth.

   - [Amazon](https://www.amazon.com/Classification-Regression-Wadsworth-Statistics-Probability/dp/0412048418)
   - [Taylor & Francis](https://www.taylorfrancis.com/books/mono/10.1201/9781315139470/classification-regression-trees-leo-breiman)

#### Instance-Based Learning

10. **Cover, T., & Hart, P.** (1967). Nearest neighbor pattern classification. *IEEE Transactions on Information Theory*, 13(1), 21-27.

    - [DOI: 10.1109/TIT.1967.1053964](https://doi.org/10.1109/TIT.1967.1053964)
    - [IEEE Xplore](https://ieeexplore.ieee.org/document/1053964)

11. **Aha, D. W., Kibler, D., & Albert, M. K.** (1991). Instance-based learning algorithms. *Machine Learning*, 6(1), 37-66.

    - [DOI: 10.1023/A:1022689900470](https://doi.org/10.1023/A:1022689900470)
    - [PDF](https://link.springer.com/article/10.1023/A:1022689900470)

#### Support Vector Machines

12. **Cortes, C., & Vapnik, V.** (1995). Support-vector networks. *Machine Learning*, 20(3), 273-297.

    - [DOI: 10.1007/BF00994018](https://doi.org/10.1007/BF00994018)
    - [PDF](https://link.springer.com/article/10.1007/BF00994018)

13. **Vapnik, V. N.** (1998). *Statistical Learning Theory*. Wiley.

    - [Amazon](https://www.amazon.com/Statistical-Learning-Theory-Vladimir-Vapnik/dp/0471030031)
    - [Wiley](https://www.wiley.com/en-us/Statistical+Learning+Theory-p-9780471030034)

14. **Vapnik, V., & Chervonenkis, A.** (1971). On the uniform convergence of relative frequencies of events to their probabilities. *Theory of Probability and its Applications*, 16(2), 264-280. (VC Dimension)

    - [DOI: 10.1137/1116025](https://doi.org/10.1137/1116025)
    - [PDF](https://epubs.siam.org/doi/abs/10.1137/1116025)

#### Neural Networks

15. **Rumelhart, D. E., Hinton, G. E., & Williams, R. J.** (1986). Learning representations by back-propagating errors. *Nature*, 323(6088), 533-536.

    - [DOI: 10.1038/323533a0](https://doi.org/10.1038/323533a0)
    - [Nature](https://www.nature.com/articles/323533a0)
    - [PDF](https://www.nature.com/articles/323533a0.pdf)

16. **Hornik, K., Stinchcombe, M., & White, H.** (1989). Multilayer feedforward networks are universal approximators. *Neural Networks*, 2(5), 359-366.

    - [DOI: 10.1016/0893-6080(89)90020-8](https://doi.org/10.1016/0893-6080(89)90020-8)
    - [PDF](https://www.sciencedirect.com/science/article/abs/pii/0893608089900208)

17. **Goodfellow, I., Bengio, Y., & Courville, A.** (2016). *Deep Learning*. MIT Press.

    - [MIT Press](https://mitpress.mit.edu/9780262035613/deep-learning/)
    - [Free Online Book](https://www.deeplearningbook.org/)
    - [Amazon](https://www.amazon.com/Deep-Learning-Adaptive-Computation-Machine/dp/0262035618)

#### Genetic Algorithms

18. **Holland, J. H.** (1975). *Adaptation in Natural and Artificial Systems*. University of Michigan Press.

    - [Amazon](https://www.amazon.com/Adaptation-Natural-Artificial-Systems-Introductory/dp/0262581116)
    - [MIT Press (Reprint)](https://mitpress.mit.edu/9780262581110/adaptation-in-natural-and-artificial-systems/)

19. **Goldberg, D. E.** (1989). *Genetic Algorithms in Search, Optimization, and Machine Learning*. Addison-Wesley.

    - [Amazon](https://www.amazon.com/Genetic-Algorithms-Search-Optimization-Machine/dp/0201157675)
    - [Pearson](https://www.pearson.com/en-us/subject-catalog/p/genetic-algorithms-in-search-optimization-and-machine-learning/P200000003431)

20. **Mitchell, M.** (1998). *An Introduction to Genetic Algorithms*. MIT Press.

    - [MIT Press](https://mitpress.mit.edu/9780262631853/an-introduction-to-genetic-algorithms/)
    - [Amazon](https://www.amazon.com/Introduction-Genetic-Algorithms-Complex-Adaptive/dp/0262631857)

#### Statistical Learning Theory

21. **Hastie, T., Tibshirani, R., & Friedman, J.** (2009). *The Elements of Statistical Learning: Data Mining, Inference, and Prediction* (2nd Edition). Springer.

    - [Springer](https://link.springer.com/book/10.1007/978-0-387-84858-7)
    - [Free PDF (Author's Website)](https://hastie.su.domains/ElemStatLearn/)
    - [Amazon](https://www.amazon.com/Elements-Statistical-Learning-Prediction-Statistics/dp/0387848576)

22. **Mohri, M., Rostamizadeh, A., & Talwalkar, A.** (2018). *Foundations of Machine Learning* (2nd Edition). MIT Press.

    - [MIT Press](https://mitpress.mit.edu/9780262039406/foundations-of-machine-learning-second-edition/)
    - [Free PDF (Author's Website)](https://cs.nyu.edu/~mohri/mlbook/)
    - [Amazon](https://www.amazon.com/Foundations-Machine-Learning-Adaptive-Computation/dp/0262039400)

#### Reinforcement Learning

23. **Sutton, R. S., & Barto, A. G.** (2018). *Reinforcement Learning: An Introduction* (2nd Edition). MIT Press.

    - [MIT Press](https://mitpress.mit.edu/9780262039246/reinforcement-learning-second-edition/)
    - [Free Online Book](http://incompleteideas.net/book/the-book-2nd.html)
    - [Amazon](https://www.amazon.com/Reinforcement-Learning-Introduction-Adaptive-Computation/dp/0262039249)

24. **Szepesv√°ri, C.** (2010). *Algorithms for Reinforcement Learning*. Morgan & Claypool.

    - [Morgan & Claypool](https://www.morganclaypool.com/doi/abs/10.2200/S00268ED1V01Y201005AIM009)
    - [Free PDF](https://sites.ualberta.ca/~szepesva/papers/RLAlgsInMDPs.pdf)
    - [Amazon](https://www.amazon.com/Algorithms-Reinforcement-Learning-Synthesis-Artificial/dp/1608454924)

## Online Resources

### Course Materials

- **Course GitHub Repository**: [https://github.com/shivam2003-dev/made_for_ml](https://github.com/shivam2003-dev/made_for_ml)
- **Course Website**: [https://shivam2003-dev.github.io/made_for_ml](https://shivam2003-dev.github.io/made_for_ml)
- Jupyter Notebooks: Interactive implementations of algorithms
- Code Examples: Python implementations from scratch

### Additional Learning Resources

- **Scikit-learn Documentation**: [https://scikit-learn.org/](https://scikit-learn.org/)
- **TensorFlow Tutorials**: [https://www.tensorflow.org/learn](https://www.tensorflow.org/learn)
- **PyTorch Tutorials**: [https://pytorch.org/tutorials/](https://pytorch.org/tutorials/)
- **Kaggle Learn**: [https://www.kaggle.com/learn](https://www.kaggle.com/learn)
- **Fast.ai**: [https://www.fast.ai/](https://www.fast.ai/)
- **Andrew Ng's Machine Learning Course**: [https://www.coursera.org/learn/machine-learning](https://www.coursera.org/learn/machine-learning)

### Mathematical Foundations

- **Linear Algebra**: Strang, G. (2016). *Introduction to Linear Algebra* (5th Edition). Wellesley-Cambridge Press.
  - [MIT OpenCourseWare](https://ocw.mit.edu/courses/18-06-linear-algebra-spring-2010/)
  - [Amazon](https://www.amazon.com/Introduction-Linear-Algebra-Gilbert-Strang/dp/0980232775)

- **Probability Theory**: Ross, S. M. (2014). *A First Course in Probability* (9th Edition). Pearson.
  - [Pearson](https://www.pearson.com/en-us/subject-catalog/p/a-first-course-in-probability/P200000003431)
  - [Amazon](https://www.amazon.com/First-Course-Probability-9th/dp/032179477X)

- **Optimization**: Boyd, S., & Vandenberghe, L. (2004). *Convex Optimization*. Cambridge University Press.
  - [Free PDF (Author's Website)](https://web.stanford.edu/~boyd/cvxbook/)
  - [Cambridge University Press](https://www.cambridge.org/core/books/convex-optimization/4E2441464410C231773A45BC5F5C52FA)
  - [Amazon](https://www.amazon.com/Convex-Optimization-Stephen-Boyd/dp/0521833787)

### Research Databases

- **Google Scholar**: [https://scholar.google.com/](https://scholar.google.com/)
- **arXiv**: [https://arxiv.org/](https://arxiv.org/) (Preprints in ML, AI, Statistics)
- **IEEE Xplore**: [https://ieeexplore.ieee.org/](https://ieeexplore.ieee.org/)
- **ACM Digital Library**: [https://dl.acm.org/](https://dl.acm.org/)
- **SpringerLink**: [https://link.springer.com/](https://link.springer.com/)

## Citation Format

When citing these references in your work, use standard academic citation formats (APA, IEEE, etc.). For example:

**APA Style**:
Mitchell, T. M. (1997). *Machine Learning*. The McGraw-Hill Companies, Inc.

**IEEE Style**:
T. M. Mitchell, *Machine Learning*. New York, NY, USA: McGraw-Hill, 1997.

**BibTeX Example**:
```bibtex
@book{mitchell1997machine,
  title={Machine Learning},
  author={Mitchell, Tom M},
  year={1997},
  publisher={McGraw-Hill}
}
```

---

*This reference list is not exhaustive. Additional papers and resources may be added as the course evolves.*
