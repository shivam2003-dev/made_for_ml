# References

## Primary Textbooks

### T1: Machine Learning by Tom M. Mitchell

**Mitchell, T. M.** (1997). *Machine Learning*. The McGraw-Hill Companies, Inc. Indian Edition.

This is the primary textbook for the course, covering fundamental concepts in machine learning including:
- Decision tree learning
- Neural networks
- Bayesian learning
- Instance-based learning
- Genetic algorithms

**Key Chapters**:
- Chapter 1: Introduction
- Chapter 3: Decision Tree Learning
- Chapter 4: Artificial Neural Networks
- Chapter 6: Bayesian Learning
- Chapter 8: Instance-Based Learning
- Chapter 9: Genetic Algorithms

### R1: Pattern Recognition & Machine Learning by Christopher M. Bishop

**Bishop, C. M.** (2006). *Pattern Recognition & Machine Learning*. Springer.

A comprehensive text with strong mathematical foundations, covering:
- Linear models for regression and classification
- Neural networks
- Kernel methods
- Bayesian approaches

**Key Chapters**:
- Chapter 1: Introduction
- Chapter 3: Linear Models for Regression
- Chapter 4: Linear Models for Classification
- Chapter 5: Neural Networks
- Chapter 7: Sparse Kernel Machines (SVMs)

### R2: Introduction to Data Mining by Tan, Steinbach, and Kumar

**Tan, P. N., Steinbach, M., & Kumar, V.** (2019). *Introduction To Data Mining* (2nd Edition). Pearson.

Focuses on practical data mining techniques and algorithms:
- Classification
- Clustering
- Association analysis
- Anomaly detection

## Additional References

### Support Vector Machines

**Burges, C. J. C.** (1998). A Tutorial on Support Vector Machines for Pattern Recognition. *Data Mining and Knowledge Discovery*, 2(2), 121-167.

Comprehensive tutorial covering:
- Mathematical foundations of SVMs
- Kernel methods
- Practical implementation considerations

### Research Papers

#### Bayesian Learning

1. **Domingos, P., & Pazzani, M.** (1997). On the optimality of the simple Bayesian classifier under zero-one loss. *Machine Learning*, 29(2-3), 103-130.

2. **Rissanen, J.** (1978). Modeling by shortest data description. *Automatica*, 14(5), 465-471. (MDL Principle)

#### Model Selection

3. **Geman, S., Bienenstock, E., & Doursat, R.** (1992). Neural networks and the bias/variance dilemma. *Neural Computation*, 4(1), 1-58.

4. **Kohavi, R.** (1995). A study of cross-validation and bootstrap for accuracy estimation and model selection. *IJCAI*, 14(2), 1137-1145.

#### Linear Models

5. **Tibshirani, R.** (1996). Regression shrinkage and selection via the lasso. *Journal of the Royal Statistical Society*, 58(1), 267-288.

6. **Hoerl, A. E., & Kennard, R. W.** (1970). Ridge regression: Biased estimation for nonorthogonal problems. *Technometrics*, 12(1), 55-67.

#### Decision Trees

7. **Quinlan, J. R.** (1986). Induction of decision trees. *Machine Learning*, 1(1), 81-106. (ID3 Algorithm)

8. **Quinlan, J. R.** (1993). *C4.5: Programs for Machine Learning*. Morgan Kaufmann.

9. **Breiman, L., Friedman, J., Stone, C. J., & Olshen, R. A.** (1984). *Classification and Regression Trees*. Wadsworth.

#### Instance-Based Learning

10. **Cover, T., & Hart, P.** (1967). Nearest neighbor pattern classification. *IEEE Transactions on Information Theory*, 13(1), 21-27.

11. **Aha, D. W., Kibler, D., & Albert, M. K.** (1991). Instance-based learning algorithms. *Machine Learning*, 6(1), 37-66.

#### Support Vector Machines

12. **Cortes, C., & Vapnik, V.** (1995). Support-vector networks. *Machine Learning*, 20(3), 273-297.

13. **Vapnik, V. N.** (1998). *Statistical Learning Theory*. Wiley.

14. **Vapnik, V., & Chervonenkis, A.** (1971). On the uniform convergence of relative frequencies of events to their probabilities. *Theory of Probability and its Applications*, 16(2), 264-280. (VC Dimension)

#### Neural Networks

15. **Rumelhart, D. E., Hinton, G. E., & Williams, R. J.** (1986). Learning representations by back-propagating errors. *Nature*, 323(6088), 533-536.

16. **Hornik, K., Stinchcombe, M., & White, H.** (1989). Multilayer feedforward networks are universal approximators. *Neural Networks*, 2(5), 359-366.

17. **Goodfellow, I., Bengio, Y., & Courville, A.** (2016). *Deep Learning*. MIT Press.

#### Genetic Algorithms

18. **Holland, J. H.** (1975). *Adaptation in Natural and Artificial Systems*. University of Michigan Press.

19. **Goldberg, D. E.** (1989). *Genetic Algorithms in Search, Optimization, and Machine Learning*. Addison-Wesley.

20. **Mitchell, M.** (1998). *An Introduction to Genetic Algorithms*. MIT Press.

#### Statistical Learning Theory

21. **Hastie, T., Tibshirani, R., & Friedman, J.** (2009). *The Elements of Statistical Learning: Data Mining, Inference, and Prediction* (2nd Edition). Springer.

22. **Mohri, M., Rostamizadeh, A., & Talwalkar, A.** (2018). *Foundations of Machine Learning* (2nd Edition). MIT Press.

#### Reinforcement Learning

23. **Sutton, R. S., & Barto, A. G.** (2018). *Reinforcement Learning: An Introduction* (2nd Edition). MIT Press.

24. **Szepesv√°ri, C.** (2010). *Algorithms for Reinforcement Learning*. Morgan & Claypool.

## Online Resources

### Course Materials

- Course GitHub Repository: [Link to be added]
- Jupyter Notebooks: Interactive implementations of algorithms
- Code Examples: Python implementations from scratch

### Additional Learning Resources

- **Scikit-learn Documentation**: https://scikit-learn.org/
- **TensorFlow Tutorials**: https://www.tensorflow.org/learn
- **PyTorch Tutorials**: https://pytorch.org/tutorials/
- **Kaggle Learn**: https://www.kaggle.com/learn

### Mathematical Foundations

- **Linear Algebra**: Strang, G. (2016). *Introduction to Linear Algebra* (5th Edition). Wellesley-Cambridge Press.
- **Probability Theory**: Ross, S. M. (2014). *A First Course in Probability* (9th Edition). Pearson.
- **Optimization**: Boyd, S., & Vandenberghe, L. (2004). *Convex Optimization*. Cambridge University Press.

## Citation Format

When citing these references in your work, use standard academic citation formats (APA, IEEE, etc.). For example:

**APA Style**:
Mitchell, T. M. (1997). *Machine Learning*. The McGraw-Hill Companies, Inc.

**IEEE Style**:
T. M. Mitchell, *Machine Learning*. New York, NY, USA: McGraw-Hill, 1997.

---

*This reference list is not exhaustive. Additional papers and resources may be added as the course evolves.*

